{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MetaboKiller_ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMyYf0vY63bC"
      },
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kryE_GtH662O"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msXXHbEQr8Us"
      },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKLHqcdQn3pH"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "#import conda_installer\n",
        "#conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyarbZiXn9RY"
      },
      "source": [
        "!pip install --pre deepchem\n",
        "import deepchem as dc\n",
        "dc.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WLFTO7DoHsW"
      },
      "source": [
        "!pip install mordred\n",
        "!pip install boruta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbB1batF3IS3"
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-py37_4.8.3-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vqLHsZGUGP8"
      },
      "source": [
        "!pip install dgl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOwTW-IHURbc"
      },
      "source": [
        "!pip install dgllife\n",
        "!pip install imblearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOrrlq1unwL3"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import deepchem as dc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from statistics import mean\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "from deepchem.feat import MolGraphConvFeaturizer\n",
        "from deepchem.feat.graph_data import GraphData\n",
        "from deepchem.feat.mol_graphs import ConvMol\n",
        "from deepchem.data import NumpyDataset\n",
        "from mordred import Calculator, descriptors\n",
        "from rdkit import Chem\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score,cohen_kappa_score,f1_score,precision_score,recall_score\n",
        "from collections import Counter\n",
        "import sys\n",
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
        "import warnings\n",
        "from boruta import BorutaPy\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akKARm60oaTV"
      },
      "source": [
        "#1. Remove invalid samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMyuZLNtelBG"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ensemble/Data/input.csv')\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45wsl_Biqw4R"
      },
      "source": [
        "1.1 MolGraphConv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7d7_6pztAZ"
      },
      "source": [
        "def generate_dataset(data,feat):  \n",
        "  smiles = data['smiles']\n",
        "  featurizer = feat\n",
        "  features = featurizer.featurize(smiles)  \n",
        "  indices = [ i for i, data in enumerate(features) if type(data) is not GraphData] #indices which failed to featurize  \n",
        "  return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMhiEhpZgNR4"
      },
      "source": [
        "#input data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ensemble/Data/input.csv')\n",
        "data = data\n",
        "feat = dc.feat.MolGraphConvFeaturizer()\n",
        "while True:# remove all error producing samples\n",
        "  indices = generate_dataset(data,feat)\n",
        "  if len(indices) > 0: #keep removing unless there are no error prone samples\n",
        "    data.drop(index=indices,inplace=True)\n",
        "  else:\n",
        "    break\n",
        "  print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZKPVNGgn5L"
      },
      "source": [
        "data.to_csv('/content/drive/MyDrive/ensemble/Data/input_molgraphconv.csv',index=False)#After 1st level of filtering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVcT-0vPrwdG"
      },
      "source": [
        "1.2 ConvMol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xGdvB58runO"
      },
      "source": [
        "def generate_dataset(data,feat):  \n",
        "  smiles = data['smiles']\n",
        "  featurizer = feat\n",
        "  features = featurizer.featurize(smiles)  \n",
        "  indices = [ i for i, data in enumerate(features) if type(data) is not ConvMol]   \n",
        "  return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29hL8Lglh6b_"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ensemble/Data/input_molgraphconv.csv')\n",
        "feat = dc.feat.ConvMolFeaturizer()\n",
        "while True:# remove all error producing samples\n",
        "  indices = generate_dataset(data,feat)\n",
        "  if len(indices) > 0: #keep removing unless there are no error prone samples\n",
        "    data.drop(index=indices,inplace=True)\n",
        "  else:\n",
        "    break\n",
        "  print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnqhJqUdh6cL"
      },
      "source": [
        "data.to_csv('/content/drive/MyDrive/ensemble/Data/input_clean.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciDYDfnit8Pw"
      },
      "source": [
        "#2. Extract Mordred Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG7FmaWwuaR8"
      },
      "source": [
        "2.1 Apoptosis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIbZCp30tH6V"
      },
      "source": [
        "data1 = pd.read_csv('/content/drive/MyDrive/ensemble/Data/apoptosis.csv')\n",
        "data2 = pd.read_csv('/content/drive/MyDrive/ensemble/Data/input_clean.csv')\n",
        "data2.head()\n",
        "print(len(data1),len(data2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmIpJNHd4IGD"
      },
      "source": [
        "data = pd.concat((data1,data2),axis=0)\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqEprEM-kaAM"
      },
      "source": [
        "#input\n",
        "def extract_features(data): #extracting mordred features for apoptosis data\n",
        "  calc = Calculator(descriptors)\n",
        "  mols = [Chem.MolFromSmiles(smi) for smi in data[\"smiles\"]]  \n",
        "  df = calc.pandas(mols)  ## All features  \n",
        "  df[\"status\"] = data[\"status\"].values   \n",
        "  df.to_csv('/content/drive/MyDrive/ensemble/Data/apoptosis_input_mordred.csv',index=False)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4JP3DpvlUI"
      },
      "source": [
        "feat = extract_features(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nYx-u5ev6QM"
      },
      "source": [
        "2.2 Cell Proliferations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ-elt5xntFS"
      },
      "source": [
        "data1 = pd.read_csv('/content/drive/MyDrive/ensemble/Data/cell_proliferation.csv')\n",
        "data1 = data1[['name','smiles','status']]\n",
        "data2 = pd.read_csv('/content/drive/MyDrive/ensemble/Data/input_clean.csv')\n",
        "data2 = data2[['name','smiles']]\n",
        "data2['status'] = [0]*len(data2) #to maintain consistency\n",
        "print(len(data1),len(data2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmsMrgxiwgoH"
      },
      "source": [
        "data = pd.concat((data1,data2),axis=0)\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OguOXXpNtGqS"
      },
      "source": [
        "#input\n",
        "def extract_features(data): #extracting mordred features for cell_proliferation data\n",
        "  calc = Calculator(descriptors)\n",
        "  mols = [Chem.MolFromSmiles(smi) for smi in data[\"smiles\"]]  \n",
        "  df = calc.pandas(mols)  ## All features  \n",
        "  df[\"status\"] = data[\"status\"].values   \n",
        "  df.to_csv('/content/drive/MyDrive/ensemble/Data/proliferations_input_mordred.csv',index=False)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czm-uehN217q"
      },
      "source": [
        "feat = extract_features(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xqy7cfEzRiG"
      },
      "source": [
        "print(len(feat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH6NfoPJw8k7"
      },
      "source": [
        "#3. Ensemble Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnHFhK9OxpAw"
      },
      "source": [
        "3.1 Preprocessing for ML Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56cOmKHRxooS"
      },
      "source": [
        "def perform_column_pruning(data,th=75):\n",
        "  data = data.replace(r'\\s+', np.nan, regex=True)\n",
        "  data[data == np.inf] = np.nan\n",
        "  data = data.replace(r'^\\s*$', np.nan, regex=True)  \n",
        "\n",
        "  na_sum_series = data.isna().mean()\n",
        "  org_data = data.copy()\n",
        "\n",
        "  NAN_data = pd.DataFrame({0: na_sum_series.index, 1: na_sum_series.values})\n",
        "  dropped = []\n",
        "  for i in range(len(NAN_data)):\n",
        "      if NAN_data.iloc[i][1] >= (th / 100):  # TODO check if sum or sum/length i.e. avg greater than threshold\n",
        "          dropped.append(NAN_data.iloc[i][0])\n",
        "  data = data.drop(dropped, axis=1)\n",
        "  return data\n",
        "\n",
        "def handle_missing_values(data):#imputation by mean\n",
        "  data = data.replace([np.inf, -np.inf, \"\", \" \"], np.nan)\n",
        "  data = data.replace([\"\", \" \"], np.nan)\n",
        "  data.fillna(data.mean(), inplace=True)\n",
        "  return data\n",
        "\n",
        "def smote_imb(xtrain, ytrain): #upsampling by SMOTE technique\n",
        "        print('Inside SMOTE, Original dataset shape %s' % Counter(ytrain))        \n",
        "        sm = SMOTE(random_state=50)\n",
        "        xtrain_new, ytrain_new = sm.fit_resample(xtrain, ytrain)        \n",
        "        print('Inside SMOTE, Resampled dataset shape %s' % Counter(ytrain_new))\n",
        "        return xtrain_new, ytrain_new\n",
        "\n",
        "def boruta_fs(xtrain, xtest, ytrain): #boruta feature selector\n",
        "    print(\"Inside BorutaFS, Before Shape Train: \", xtrain.shape)\n",
        "    print(\"Inside BorutaFS, Before Shape Test: \", xtest.shape)\n",
        "    rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
        "    boruta_selector = BorutaPy(rfc, n_estimators='auto', random_state=50)\n",
        "    boruta_selector.fit(xtrain, ytrain)\n",
        "    xtrain_sel = boruta_selector.transform(xtrain)\n",
        "    xtest_sel = boruta_selector.transform(xtest.values)\n",
        "    print(\"Inside BorutaFS, After Shape Train: \", xtrain_sel.shape)\n",
        "    print(\"Inside BorutaFS,  After Shape Test: \", xtest_sel.shape)    \n",
        "    return xtrain_sel, xtest_sel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z14G73DxL5f"
      },
      "source": [
        "3.2 Model Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpO9B9nhxCFv"
      },
      "source": [
        "class model_epigenetic: #Model1\n",
        "    def __init__(self,train,test): #initialise train and test set       \n",
        "        self.train = train\n",
        "        self.test = test\n",
        "    def extract_feature(self,data): #generate dataset        \n",
        "        labels = data['status']\n",
        "        smiles = data['smiles']\n",
        "        featurizer = dc.feat.MolGraphConvFeaturizer()\n",
        "        features = featurizer.featurize(smiles)            \n",
        "        dataset = NumpyDataset(features,labels)  \n",
        "        return dataset \n",
        "    def get_labels(self,pred_test): #Getting discrete labels from probability values    \n",
        "        test_pred = []        \n",
        "        for i in range(pred_test.shape[0]):\n",
        "            if(pred_test[i][0]>pred_test[i][1]):\n",
        "                test_pred.append(0)\n",
        "            else:\n",
        "                test_pred.append(1)\n",
        "        return test_pred \n",
        "    def train_model(self):\n",
        "        train = self.train \n",
        "        X = train['smiles']\n",
        "        y = train['status']\n",
        "        X_train = X\n",
        "        y_train = y\n",
        "        sampler = RandomOverSampler(sampling_strategy='minority') #Upsampling of minority class samples\n",
        "        X_train = X_train.to_numpy()\n",
        "        X_train = X_train.reshape((-1,1))\n",
        "        X_train,y_train = sampler.fit_resample(X_train,y_train)\n",
        "        data_train = pd.DataFrame(columns=['status','smiles'])\n",
        "        data_train['status'] = y_train\n",
        "        data_train['smiles'] = X_train                      \n",
        "        train_dataset = self.extract_feature(data_train) #generating train dataset\n",
        "        model = dc.models.GCNModel(n_tasks=1,mode='classification',graph_conv_layers=[64,64], predictor_hidden_feats=64,\n",
        "        predictor_dropout = 0.2, Learning_rate = 0.001, batch_size = 32,model_dir='/content/drive/MyDrive/ensemble/models/model_epigenetic')\n",
        "        #saves the trained model in model_dir\n",
        "        model.fit(train_dataset,nb_epoch=100) #training for 100 epochs\n",
        "       \n",
        "    def test_model(self):\n",
        "        test = self.test\n",
        "        test_dataset = self.extract_feature(test) #generating test dataset\n",
        "        model = dc.models.GCNModel(n_tasks=1,mode='classification',graph_conv_layers=[64,64], predictor_hidden_feats=64,\n",
        "        predictor_dropout = 0.2, Learning_rate = 0.001, batch_size = 32,model_dir='/content/drive/MyDrive/ensemble/models/model_epigenetic')\n",
        "        model.restore() #restore the trained model from model_dir\n",
        "        probs = model.predict(test_dataset)    \n",
        "        preds = self.get_labels(probs)\n",
        "        return probs,preds\n",
        "\n",
        "\n",
        "class model_oxidative:  #Model 2  \n",
        "    def __init__(self,train,test):        \n",
        "        self.train = train\n",
        "        self.test = test\n",
        "    def extract_feature(self,data):        \n",
        "        labels = data['status']\n",
        "        smiles = data['smiles']\n",
        "        featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True) #use_edges=True for Attentive FP Model\n",
        "        features = featurizer.featurize(smiles)            \n",
        "        dataset = NumpyDataset(features,labels)  \n",
        "        return dataset \n",
        "    def get_labels(self,pred_test): #Getting discrete labels from probability values    \n",
        "        test_pred = []        \n",
        "        for i in range(pred_test.shape[0]):\n",
        "            if(pred_test[i][0]>pred_test[i][1]):\n",
        "                test_pred.append(0)\n",
        "            else:\n",
        "                test_pred.append(1)\n",
        "        return test_pred \n",
        "    def train_model(self):\n",
        "        train = self.train \n",
        "        X = train['smiles']\n",
        "        y = train['status']\n",
        "        X_train = X\n",
        "        y_train = y\n",
        "        sampler = RandomOverSampler(sampling_strategy='minority')\n",
        "        X_train = X_train.to_numpy()\n",
        "        X_train = X_train.reshape((-1,1))\n",
        "        X_train,y_train = sampler.fit_resample(X_train,y_train)\n",
        "        data_train = pd.DataFrame(columns=['status','smiles'])\n",
        "        data_train['status'] = y_train\n",
        "        data_train['smiles'] = X_train                      \n",
        "        train_dataset = self.extract_feature(data_train)\n",
        "        model = dc.models.AttentiveFPModel(n_tasks=1,mode='classification',num_layers=2,graph_feat_size=200,dropout=0.5,batch_size=32, learning_rate=0.001,model_dir='/content/drive/MyDrive/ensemble/models/model_oxidative')\n",
        "        model.fit(train_dataset,nb_epoch=100)\n",
        "       \n",
        "    def test_model(self):\n",
        "        test = self.test\n",
        "        test_dataset = self.extract_feature(test)\n",
        "        model = dc.models.AttentiveFPModel(n_tasks=1,mode='classification',num_layers=2,graph_feat_size=200,dropout=0.5,batch_size=32, learning_rate=0.001,model_dir='/content/drive/MyDrive/ensemble/models/model_oxidative')\n",
        "        model.restore()\n",
        "        probs = model.predict(test_dataset)    \n",
        "        preds = self.get_labels(probs)\n",
        "        return probs,preds\n",
        "\n",
        "class model_genotoxic: #Model 3\n",
        "    def __init__(self,train,test):        \n",
        "        self.train = train\n",
        "        self.test = test\n",
        "    def extract_feature(self,data):        \n",
        "        labels = data['status']\n",
        "        smiles = data['smiles']\n",
        "        featurizer = dc.feat.ConvMolFeaturizer()\n",
        "        features = featurizer.featurize(smiles)            \n",
        "        dataset = NumpyDataset(features,labels)  \n",
        "        return dataset \n",
        "    def get_labels(self,pred_test): #Getting discrete labels from probability values    \n",
        "        test_pred = []        \n",
        "        for i in range(pred_test.shape[0]):\n",
        "            if(pred_test[i][0][0]>pred_test[i][0][1]):\n",
        "                test_pred.append(0)\n",
        "            else:\n",
        "                test_pred.append(1)\n",
        "        return test_pred \n",
        "    def train_model(self):\n",
        "        train = self.train                             \n",
        "        train_dataset = self.extract_feature(train)\n",
        "        model = dc.models.GraphConvModel(mode='classification',n_tasks=1,batch_size=32,learning_rate=0.001,model_dir='/content/drive/MyDrive/ensemble/models/model_genotoxic')\n",
        "        model.fit(train_dataset,nb_epoch=100)\n",
        "       \n",
        "    def test_model(self):\n",
        "        test = self.test\n",
        "        test_dataset = self.extract_feature(test)\n",
        "        model = dc.models.GraphConvModel(mode='classification',n_tasks=1,batch_size=32,learning_rate=0.001,model_dir='/content/drive/MyDrive/ensemble/models/model_genotoxic')\n",
        "        model.restore()\n",
        "        probs = model.predict(test_dataset)    \n",
        "        preds = self.get_labels(probs)\n",
        "        return probs,preds\n",
        "\n",
        "class model_electrophiles: #Model 4\n",
        "    def __init__(self,train,test):        \n",
        "        self.train = train\n",
        "        self.test = test\n",
        "    def extract_feature(self,data):        \n",
        "        labels = data['status']\n",
        "        smiles = data['smiles']\n",
        "        featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
        "        features = featurizer.featurize(smiles)            \n",
        "        dataset = NumpyDataset(features,labels)  \n",
        "        return dataset \n",
        "    def get_labels(self,pred_test): #Getting discrete labels from probability values    \n",
        "        test_pred = []   \n",
        "        print(pred_test.shape)     \n",
        "        for i in range(pred_test.shape[0]):\n",
        "            if(pred_test[i][0]>pred_test[i][1]):\n",
        "                test_pred.append(0)\n",
        "            else:\n",
        "                test_pred.append(1)\n",
        "        return test_pred \n",
        "    def train_model(self):\n",
        "        train = self.train         \n",
        "        X = train['smiles']\n",
        "        y = train['status']\n",
        "        X_train = X\n",
        "        y_train = y\n",
        "        sampler = RandomOverSampler(sampling_strategy='minority')\n",
        "        X_train = X_train.to_numpy()\n",
        "        X_train = X_train.reshape((-1,1))\n",
        "        X_train,y_train = sampler.fit_resample(X_train,y_train)\n",
        "        data_train = pd.DataFrame(columns=['status','smiles'])\n",
        "        data_train['status'] = y_train\n",
        "        data_train['smiles'] = X_train                      \n",
        "        train_dataset = self.extract_feature(data_train)\n",
        "        model = dc.models.AttentiveFPModel(n_tasks=1,mode='classification',num_layers=2,graph_feat_size=200,dropout=0,batch_size=32, learning_rate=0.001,model_dir='/content/drive/MyDrive/ensemble/models/model_electrophiles_final')\n",
        "        model.fit(train_dataset,nb_epoch=100)        \n",
        "\n",
        "    def test_model(self):\n",
        "        test = self.test\n",
        "        test_dataset = self.extract_feature(test)\n",
        "        model = dc.models.AttentiveFPModel(n_tasks=1,mode='classification',num_layers=2,graph_feat_size=200,dropout=0,batch_size=32, learning_rate=0.001,model_dir='/content/drive/MyDrive/ensemble/models/model_electrophiles_final')\n",
        "        model.restore()\n",
        "        probs = model.predict(test_dataset)    \n",
        "        preds = self.get_labels(probs)\n",
        "        return probs,preds\n",
        "\n",
        "class model_apoptosis: #Model 5\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "\n",
        "    def preprocess(self): \n",
        "        data = self.data                   \n",
        "        labels = data['status']\n",
        "        data.drop(columns=[\"status\"],inplace=True)  \n",
        "        y_train = labels.iloc[:569]     \n",
        "        y_test = labels.iloc[569:]\n",
        "        data[data.columns] = data[data.columns].apply(pd.to_numeric,errors='coerce')        \n",
        "        data = perform_column_pruning(data)\n",
        "        train = data.iloc[:569,:]\n",
        "        test = data.iloc[569:,:]        \n",
        "        train = handle_missing_values(train).values        \n",
        "        test = handle_missing_values(test)\n",
        "        x_train = train\n",
        "        x_test = test                      \n",
        "        x_train,y_train = smote_imb(x_train,y_train)     \n",
        "        x_train, x_test = boruta_fs(x_train, x_test, y_train)\n",
        "        self.x_train,self.y_train,self.x_test,self.y_test = x_train,y_train,x_test,y_test\n",
        "    \n",
        "    def train_model(self):\n",
        "        x_train,y_train = self.x_train,self.y_train        \n",
        "        rf = RandomForestClassifier(n_estimators=100,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=100,bootstrap=False)\n",
        "        rf.fit(x_train,y_train)        \n",
        "        joblib.dump(rf, '/content/drive/MyDrive/ensemble/models/model_apoptosis.sav')\n",
        "\n",
        "    def test_model(self):\n",
        "        x_test,y_test = self.x_test,self.y_test\n",
        "        rf = joblib.load('/content/drive/MyDrive/ensemble/models/model_apoptosis.sav')        \n",
        "        pred = rf.predict(x_test)\n",
        "        prob = rf.predict_proba(x_test)\n",
        "        return prob,pred\n",
        "\n",
        "class model_proliferation: #Model 6\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "\n",
        "    def preprocess(self): \n",
        "        data = self.data                   \n",
        "        labels = data['status']\n",
        "        data.drop(columns=[\"status\"],inplace=True)  \n",
        "        y_train = labels.iloc[:280]     \n",
        "        y_test = labels.iloc[280:]\n",
        "        data[data.columns] = data[data.columns].apply(pd.to_numeric,errors='coerce')        \n",
        "        data = perform_column_pruning(data)\n",
        "        train = data.iloc[:280,:]\n",
        "        test = data.iloc[280:,:]        \n",
        "        train = handle_missing_values(train).values        \n",
        "        test = handle_missing_values(test)\n",
        "        x_train = train\n",
        "        x_test = test        \n",
        "        x_train,y_train = smote_imb(x_train,y_train)     \n",
        "        x_train, x_test = boruta_fs(x_train, x_test, y_train)\n",
        "        self.x_train,self.y_train,self.x_test,self.y_test = x_train,y_train,x_test,y_test\n",
        "\n",
        "    def train_model(self):\n",
        "        x_train,y_train = self.x_train,self.y_train        \n",
        "        et = ExtraTreesClassifier(max_depth=15,n_estimators=90)\n",
        "        et.fit(x_train,y_train)                        \n",
        "        joblib.dump(et, '/content/drive/MyDrive/ensemble/models/model_proliferations.sav')        \n",
        "\n",
        "    def test_model(self):\n",
        "        x_test,y_test = self.x_test,self.y_test\n",
        "        et = joblib.load('/content/drive/MyDrive/ensemble/models/model_proliferations.sav')        \n",
        "        pred = et.predict(x_test)\n",
        "        prob = et.predict_proba(x_test)\n",
        "        return prob,pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q87oNP671JiT"
      },
      "source": [
        "3.3 Get Predictions of six models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lwRWnCzSH6n"
      },
      "source": [
        "data_test = pd.read_csv('/content/drive/MyDrive/ensemble/Data/input_clean.csv')\n",
        "data_test['status'] = [0]*len(data_test) \n",
        "#dataframe to store predictions of 6 models on carcinogen data   \n",
        "predictions = pd.DataFrame(columns=['carcinogens','smiles','epigenetic_0','epigenetic_1','epigenetic_preds',\n",
        "'oxidative_0','oxidative_1','oxidative_preds','genotoxic_0','genotoxic_1','genotoxic_preds',\n",
        "'apoptosis_0','apoptosis_1','apoptosis_preds','proliferations_0','proliferations_1','proliferations_preds',\n",
        "'electrophiles_0','electrophiles_1','electrophiles_preds','ensemble_1','ensemble_preds'])\n",
        "predictions['carcinogens'] = data_test['name'] #input\n",
        "predictions['smiles'] = data_test['smiles']\n",
        "#predictions['status'] = data_test['status']\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/ensemble/Data/epigenetic.csv')\n",
        "m1 = model_epigenetic(data_train,data_test)\n",
        "# m1.train_model()  #only need to run once - model will be saved \n",
        "data_train = pd.read_csv('/content/drive/MyDrive/ensemble/Data/oxidative.csv')\n",
        "m2 = model_oxidative(data_train,data_test)\n",
        "# m2.train_model()\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/ensemble/Data/genotoxic.csv')\n",
        "m3 = model_genotoxic(data_train,data_test)\n",
        "# m3.train_model()\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/ensemble/Data/electrophiles.csv')\n",
        "m4 = model_electrophiles(data_train,data_test)\n",
        "# m4.train_model()\n",
        "data = pd.read_csv('/content/drive/MyDrive/ensemble/Data/proliferations_input_mordred.csv') #input         \n",
        "m5 = model_proliferation(data)\n",
        "m5.preprocess()\n",
        "m5.train_model()  \n",
        "data = pd.read_csv('/content/drive/MyDrive/ensemble/Data/apoptosis_input_mordred.csv') #input        \n",
        "m6 = model_apoptosis(data)\n",
        "m6.preprocess()\n",
        "m6.train_model()\n",
        "probs,preds = m1.test_model()\n",
        "predictions['epigenetic_0'] = probs[:,0]\n",
        "predictions['epigenetic_1'] = probs[:,1]\n",
        "predictions['epigenetic_preds'] = preds    \n",
        "probs,preds = m2.test_model()\n",
        "predictions['oxidative_0'] = probs[:,0]\n",
        "predictions['oxidative_1'] = probs[:,1]\n",
        "predictions['oxidative_preds'] = preds    \n",
        "probs,preds = m3.test_model()    \n",
        "predictions['genotoxic_0'] = probs[:,0,0]\n",
        "predictions['genotoxic_1'] = probs[:,0,1]\n",
        "predictions['genotoxic_preds'] = preds\n",
        "probs,preds = m4.test_model()   \n",
        "predictions['electrophiles_0'] = probs[:,0]\n",
        "predictions['electrophiles_1'] = probs[:,1]\n",
        "predictions['electrophiles_preds'] = preds\n",
        "probs,preds = m5.test_model()\n",
        "predictions['proliferations_0'] = probs[:,0]\n",
        "predictions['proliferations_1'] = probs[:,1]\n",
        "predictions['proliferations_preds'] = preds      \n",
        "probs,preds = m6.test_model()\n",
        "predictions['apoptosis_0'] = probs[:,0]\n",
        "predictions['apoptosis_1'] = probs[:,1]\n",
        "predictions['apoptosis_preds'] = preds       \n",
        "predictions.to_csv('/content/drive/MyDrive/ensemble/result_input.csv',index=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63XswlWoSX6r"
      },
      "source": [
        "3.4 Compute model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YNe0NHzSz-o"
      },
      "source": [
        "def get_predictions(probs,thresh):\n",
        "    preds = []\n",
        "    for prob in probs:\n",
        "        if prob >= thresh:\n",
        "            preds.append(1)    \n",
        "        else:\n",
        "            preds.append(0)\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dgxkD1VS4zw"
      },
      "source": [
        "def compute_weights(pred,status,thresh):  #assign weights based on accuracy of models on validation set       \n",
        "    m1_1 = pred['epigenetic_1']    \n",
        "    m1_pred = get_predictions(m1_1,thresh)\n",
        "    m2_1 = pred['oxidative_1']\n",
        "    m2_pred = get_predictions(m2_1,thresh)\n",
        "    m3_1 = pred['genotoxic_1']\n",
        "    m3_pred = get_predictions(m3_1,thresh)\n",
        "    m4_1 = pred['apoptosis_1']    \n",
        "    m4_pred = get_predictions(m4_1,thresh)\n",
        "    m5_1 = pred['proliferations_1']\n",
        "    m5_pred = get_predictions(m5_1,thresh)\n",
        "    m6_1 = pred['electrophiles_1']\n",
        "    m6_pred = get_predictions(m6_1,thresh) \n",
        "    ranks = {} #model weights\n",
        "    ranks['epigenetic'] = accuracy_score(status,m1_pred)\n",
        "    ranks['oxidative'] = accuracy_score(status,m2_pred)\n",
        "    ranks['genotoxic'] = accuracy_score(status,m3_pred)\n",
        "    ranks['apoptosis'] = accuracy_score(status,m4_pred)\n",
        "    ranks['proliferations'] = accuracy_score(status,m5_pred)\n",
        "    ranks['electrophiles'] = accuracy_score(status,m6_pred)   \n",
        "    return ranks  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKrhIE1pTd5w"
      },
      "source": [
        "3.5 Evaluate Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpz5aviIjSxj"
      },
      "source": [
        "pred_input = pd.read_csv('/content/drive/MyDrive/ensemble/result_input.csv')\n",
        "#predictions = pred_input.drop('status',axis=1)\n",
        "x_test = pred_input\n",
        "#weights of models\n",
        "weights = {'epigenetic': 0.4640625, 'oxidative': 0.459375, 'genotoxic': 0.6296875, 'apoptosis': 1.0, 'proliferations': 0.853125, 'electrophiles': 0.5625}    \n",
        "m1_1 = list(x_test['epigenetic_1'])    \n",
        "m2_1 = list(x_test['oxidative_1'])    \n",
        "m3_1 = list(x_test['genotoxic_1'])\n",
        "m4_1 = list(x_test['apoptosis_1'])\n",
        "m5_1 = list(x_test['proliferations_1'])\n",
        "m6_1 = list(x_test['electrophiles_1'])\n",
        "print(weights)    \n",
        "probs = []\n",
        "sum = weights['epigenetic'] + weights['oxidative'] + weights['genotoxic'] + weights['apoptosis'] + weights['proliferations'] + weights['electrophiles']\n",
        "for i in range(len(m1_1)):\n",
        "    prob_ensemble = (m1_1[i]*weights['epigenetic']+m2_1[i]*weights['oxidative']+m3_1[i]*weights['genotoxic']+m4_1[i]*weights['apoptosis']+m5_1[i]*weights['proliferations']+m6_1[i]*weights['electrophiles'])/sum\n",
        "    probs.append(prob_ensemble)    \n",
        "probs = np.array(probs)\n",
        "preds = get_predictions(probs,0.5)\n",
        "pred_input['ensemble_1'] = probs\n",
        "pred_input['ensemble_preds'] = preds\n",
        "pred_input.to_csv('/content/drive/MyDrive/ensemble/result_input_final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}